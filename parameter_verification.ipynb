{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_models import MessageSql\n",
    "from fake_config import Settings\n",
    "from sqlalchemy import create_engine, asc, or_\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import dotenv\n",
    "import pendulum\n",
    "\n",
    "house_alias = 'oak'\n",
    "\n",
    "# Almost no wind (0-3 mph)\n",
    "start_ms = pendulum.datetime(2025, 1, 13, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "end_ms = pendulum.datetime(2025, 1, 13, 12, 5, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "# Some wind (5-10 mph)\n",
    "start_ms = pendulum.datetime(2025, 1, 14, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "end_ms = pendulum.datetime(2025, 1, 14, 12, 5, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "# Some more wind (10-15mph)\n",
    "start_ms = pendulum.datetime(2025, 1, 15, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "end_ms = pendulum.datetime(2025, 1, 15, 12, 5, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "# start_ms = pendulum.datetime(2025, 1, 5, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "# end_ms = pendulum.datetime(2025, 1, 5, 12, 5, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "# start_ms = pendulum.datetime(2025, 1, 16, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "# end_ms = pendulum.datetime(2025, 1, 16, 12, 5, tz=\"America/New_York\").timestamp() * 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual energy used by the house\n",
    "settings = Settings(_env_file=dotenv.find_dotenv())\n",
    "valid_password = settings.visualizer_api_password.get_secret_value()\n",
    "engine = create_engine(settings.db_url.get_secret_value())\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "messages = session.query(MessageSql).filter(\n",
    "    MessageSql.from_alias.like(f'%{house_alias}%'),\n",
    "    or_(\n",
    "        MessageSql.message_type_name == \"batched.readings\",\n",
    "        MessageSql.message_type_name == \"report\"\n",
    "        ),\n",
    "    MessageSql.message_persisted_ms >= start_ms,\n",
    "    MessageSql.message_persisted_ms <= end_ms,\n",
    ").order_by(asc(MessageSql.message_persisted_ms)).all()\n",
    "\n",
    "channels = {}\n",
    "for message in messages:\n",
    "    for channel in message.payload['ChannelReadingList']:\n",
    "        # Find the channel name\n",
    "        if message.message_type_name == 'report':\n",
    "            channel_name = channel['ChannelName']\n",
    "        elif message.message_type_name == 'batched.readings':\n",
    "            for dc in message.payload['DataChannelList']:\n",
    "                if dc['Id'] == channel['ChannelId']:\n",
    "                    channel_name = dc['Name']\n",
    "        # Store the values and times for the channel\n",
    "        if (('buffer-depth' in channel_name or ('tank' in channel_name and 'depth' in channel_name)) \n",
    "            and 'micro' not in channel_name):\n",
    "            if channel_name not in channels:\n",
    "                channels[channel_name] = {\n",
    "                    'values': channel['ValueList'],\n",
    "                    'times': channel['ScadaReadTimeUnixMsList']\n",
    "                }\n",
    "            else:\n",
    "                channels[channel_name]['values'].extend(channel['ValueList'])\n",
    "                channels[channel_name]['times'].extend(channel['ScadaReadTimeUnixMsList'])\n",
    "\n",
    "# Sort values according to time and find min/max\n",
    "for key in channels.keys():\n",
    "    sorted_times_values = sorted(zip(channels[key]['times'], channels[key]['values']))\n",
    "    sorted_times, sorted_values = zip(*sorted_times_values)\n",
    "    channels[key]['values'] = list(sorted_values)\n",
    "    channels[key]['times'] = list(sorted_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy from buffer: 4.18 kWh\n",
      "Energy from storage: 33.4 kWh\n",
      "Total energy used by house: 37.5 kWh\n"
     ]
    }
   ],
   "source": [
    "PRINT = False\n",
    "\n",
    "# Find the energy used from the buffer during the on-peak period\n",
    "first_values_buffer = []\n",
    "last_values_buffer = []\n",
    "for buffer_key in [x for x in channels if 'buffer' in x]:\n",
    "    if PRINT: \n",
    "        print('')\n",
    "        print(buffer_key)\n",
    "    # Find the value closest to the start of on-peak\n",
    "    differences = [abs(time - start_ms) for time in channels[buffer_key]['times'] if time < start_ms + 5*60*1000]\n",
    "    closest_index = differences.index(min(differences))\n",
    "    first_values_buffer.append(channels[buffer_key]['values'][closest_index])\n",
    "    if PRINT: print(f\"{first_values_buffer[-1]/1000} degC at {pendulum.from_timestamp(channels[buffer_key]['times'][closest_index]/1000, tz='America/New_York').replace(microsecond=0)}\")\n",
    "    # Find the value closest to the end of on-peak\n",
    "    differences = [abs(time - end_ms) for time in channels[buffer_key]['times']]\n",
    "    closest_index = differences.index(min(differences))\n",
    "    last_values_buffer.append(channels[buffer_key]['values'][closest_index])\n",
    "    if PRINT: print(f\"{last_values_buffer[-1]/1000} degC at {pendulum.from_timestamp(channels[buffer_key]['times'][closest_index]/1000, tz='America/New_York').replace(microsecond=0)}\")\n",
    "if len(first_values_buffer) != 4 or len(last_values_buffer) != 4:\n",
    "    print(\"Some buffer temperatures are missing\")\n",
    "else:\n",
    "    first_values_buffer = [x/1000 for x in first_values_buffer]\n",
    "    last_values_buffer = [x/1000 for x in last_values_buffer]\n",
    "    buffer_avg_before = sum(first_values_buffer)/4\n",
    "    buffer_avg_after = sum(last_values_buffer)/4\n",
    "    buffer_energy_used = 120 * 3.785 * 4.187/3600 * (buffer_avg_before - buffer_avg_after)\n",
    "\n",
    "# Find the energy used from the buffer during the on-peak period\n",
    "first_values_store = []\n",
    "last_values_store = []\n",
    "for store_key in [x for x in channels if 'tank' in x]:\n",
    "    if PRINT:\n",
    "        print('')\n",
    "        print(store_key)\n",
    "    # Get the closest value to start on onpeak\n",
    "    differences = [abs(time - start_ms) for time in channels[store_key]['times']]\n",
    "    closest_index = differences.index(min(differences))\n",
    "    first_values_store.append(channels[store_key]['values'][closest_index])\n",
    "    if PRINT: print(f\"{first_values_store[-1]/1000} degC at {pendulum.from_timestamp(channels[store_key]['times'][closest_index]/1000, tz='America/New_York').replace(microsecond=0)}\")\n",
    "    # Get the closest value to end of onpeak\n",
    "    differences = [abs(time - end_ms) for time in channels[store_key]['times']]\n",
    "    closest_index = differences.index(min(differences))\n",
    "    last_values_store.append(channels[store_key]['values'][closest_index])\n",
    "    if PRINT: print(f\"{last_values_store[-1]/1000} degC at {pendulum.from_timestamp(channels[store_key]['times'][closest_index]/1000, tz='America/New_York').replace(microsecond=0)}\")\n",
    "\n",
    "if len(first_values_store) != 12 or len(last_values_store) != 12:\n",
    "    print(\"Some storage temperatures are missing\")\n",
    "else:\n",
    "    first_values_store = [x/1000 for x in first_values_store]\n",
    "    last_values_store = [x/1000 for x in last_values_store]\n",
    "    store_avg_before = sum(first_values_store)/12\n",
    "    store_avg_after = sum(last_values_store)/12\n",
    "    store_energy_used = 3 * 120 * 3.785 * 4.187/3600 * (store_avg_before - store_avg_after)\n",
    "\n",
    "if PRINT: print('')\n",
    "print(f\"Energy from buffer: {round(buffer_energy_used,2)} kWh\") \n",
    "print(f\"Energy from storage: {round(store_energy_used,1)} kWh\")\n",
    "total_energy_used = store_energy_used+buffer_energy_used\n",
    "print(f\"Total energy used by house: {round(total_energy_used,1)} kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "def get_weather_data(latitude, longitude, start_time, end_time):    \n",
    "    \n",
    "    # Get the gridpoint info\n",
    "    url = f\"https://api.weather.gov/points/{latitude},{longitude}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching grid data: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    # Get the nearest observation station URL\n",
    "    grid_data = response.json()\n",
    "    station_url = grid_data['properties']['observationStations']\n",
    "    station_response = requests.get(station_url)\n",
    "    if station_response.status_code != 200:\n",
    "        print(f\"Error fetching station data: {station_response.status_code}\")\n",
    "        return []\n",
    "    \n",
    "    # Get the station ID (first station in the list)\n",
    "    stations = station_response.json()\n",
    "    station_id = stations['features'][0]['properties']['stationIdentifier']\n",
    "\n",
    "    # Get hourly observations from the station\n",
    "    observations_url = f\"https://api.weather.gov/stations/{station_id}/observations\"\n",
    "    params = {\n",
    "        'start': datetime.utcfromtimestamp(start_time).isoformat() + \"Z\",\n",
    "        'end': datetime.utcfromtimestamp(end_time).isoformat() + \"Z\"\n",
    "    }\n",
    "    observations_response = requests.get(observations_url, params=params)\n",
    "    if observations_response.status_code != 200:\n",
    "        print(f\"Error fetching observations data: {observations_response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    # Extract the relevant data (temperature, windSpeed)\n",
    "    observations = observations_response.json()\n",
    "    weather_data = {\n",
    "        'time': [],\n",
    "        'oat': [],\n",
    "        'ws': []\n",
    "    }\n",
    "    # print(observations['features'][0]['properties']['temperature']['unitCode'])\n",
    "    # print(observations['features'][0]['properties']['windSpeed']['unitCode'])\n",
    "    for observation in observations['features']:\n",
    "        weather_data['time'].append(datetime.fromisoformat(observation['properties']['timestamp']).astimezone(pytz.timezone('America/New_York')).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        weather_data['oat'].append(observation['properties']['temperature']['value'])\n",
    "        weather_data['ws'].append(observation['properties']['windSpeed']['value'])\n",
    "\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m required_heat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m---> 28\u001b[0m     required_heat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m required_heating_power(\u001b[43mweather_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mws\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(total_energy_used,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(required_heat,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Get energy use forecast from weather and parameters\n",
    "ALPHA = 6\n",
    "BETA = -ALPHA/55\n",
    "GAMMA = 0.25\n",
    "\n",
    "def required_heating_power(oat, ws):\n",
    "    r = ALPHA + BETA*oat + GAMMA*ws\n",
    "    return r if r>0 else 0\n",
    "\n",
    "def to_fahrenheit(t):\n",
    "    return (t * 9/5) + 32\n",
    "\n",
    "def to_mph(ws):\n",
    "    return ws * 0.621371\n",
    "\n",
    "data = get_weather_data(45.6573, -68.7098, start_ms/1000, end_ms/1000)\n",
    "sorted_items = sorted(zip(data['time'], data['oat'], data['ws']), key=lambda x: datetime.strptime(x[0], '%Y-%m-%d %H:%M:%S'))\n",
    "weather_data = {'time': [], 'oat': [], 'ws': []}\n",
    "for time, oat, ws in sorted_items:\n",
    "    weather_data['time'].append(time)\n",
    "    weather_data['oat'].append(to_fahrenheit(oat))\n",
    "    weather_data['ws'].append(to_mph(ws))\n",
    "print(weather_data['oat'])\n",
    "print(weather_data['ws'])\n",
    "\n",
    "required_heat = 0\n",
    "for i in range(5):\n",
    "    required_heat += required_heating_power(weather_data['oat'][i], weather_data['ws'][i])\n",
    "\n",
    "print(f\"\\nUsed: {round(total_energy_used,2)}\")\n",
    "print(f\"Predicted: {round(required_heat,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When there is almost no wind (0-3mph), we are predicting way to high energy use\n",
    "# When there is some wind (10-20) we are doing good\n",
    "# Again when there is less wind (4-7) we are pedicting too high energy use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "daily_dp = [50.13] * 7 + [487.63] * 5 + [54.98] * 4 + [487.63] * 4 + [50.13] * 4\n",
    "plt.step(range(24), daily_dp)\n",
    "\n",
    "daily_dp = [price + i*1 for price, i in zip(daily_dp, list(range(24)))]\n",
    "plt.step(range(24), daily_dp)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
