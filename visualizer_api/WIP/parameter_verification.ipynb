{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MessageSql\n",
    "from config import Settings\n",
    "from sqlalchemy import create_engine, asc, or_\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import dotenv\n",
    "import pendulum\n",
    "\n",
    "house_alias = 'oak'\n",
    "\n",
    "# Almost no wind (0-3 mph)\n",
    "start_ms = pendulum.datetime(2025, 1, 13, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "end_ms = pendulum.datetime(2025, 1, 13, 12, 5, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "# Some wind (5-10 mph)\n",
    "start_ms = pendulum.datetime(2025, 1, 14, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "end_ms = pendulum.datetime(2025, 1, 14, 12, 5, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "# Some more wind (10-15mph)\n",
    "start_ms = pendulum.datetime(2025, 1, 15, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "end_ms = pendulum.datetime(2025, 1, 15, 12, 5, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "# start_ms = pendulum.datetime(2025, 1, 5, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "# end_ms = pendulum.datetime(2025, 1, 5, 12, 5, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "# start_ms = pendulum.datetime(2025, 1, 16, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "# end_ms = pendulum.datetime(2025, 1, 16, 12, 5, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "start_ms = pendulum.datetime(2025, 1, 20, 23, tz=\"America/New_York\").timestamp() * 1000 \n",
    "end_ms = pendulum.datetime(2025, 1, 21, 7, tz=\"America/New_York\").timestamp() * 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual energy used by the house\n",
    "settings = Settings(_env_file=dotenv.find_dotenv())\n",
    "valid_password = settings.visualizer_api_password.get_secret_value()\n",
    "engine = create_engine(settings.db_url.get_secret_value())\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "messages = session.query(MessageSql).filter(\n",
    "    MessageSql.from_alias.like(f'%{house_alias}%'),\n",
    "    or_(\n",
    "        MessageSql.message_type_name == \"batched.readings\",\n",
    "        MessageSql.message_type_name == \"report\"\n",
    "        ),\n",
    "    MessageSql.message_persisted_ms >= start_ms,\n",
    "    MessageSql.message_persisted_ms <= end_ms,\n",
    ").order_by(asc(MessageSql.message_persisted_ms)).all()\n",
    "\n",
    "channels = {}\n",
    "for message in messages:\n",
    "    for channel in message.payload['ChannelReadingList']:\n",
    "        # Find the channel name\n",
    "        if message.message_type_name == 'report':\n",
    "            channel_name = channel['ChannelName']\n",
    "        elif message.message_type_name == 'batched.readings':\n",
    "            for dc in message.payload['DataChannelList']:\n",
    "                if dc['Id'] == channel['ChannelId']:\n",
    "                    channel_name = dc['Name']\n",
    "        # Store the values and times for the channel\n",
    "        if (('buffer-depth' in channel_name or ('tank' in channel_name and 'depth' in channel_name)) \n",
    "            and 'micro' not in channel_name):\n",
    "            if channel_name not in channels:\n",
    "                channels[channel_name] = {\n",
    "                    'values': channel['ValueList'],\n",
    "                    'times': channel['ScadaReadTimeUnixMsList']\n",
    "                }\n",
    "            else:\n",
    "                channels[channel_name]['values'].extend(channel['ValueList'])\n",
    "                channels[channel_name]['times'].extend(channel['ScadaReadTimeUnixMsList'])\n",
    "\n",
    "# Sort values according to time and find min/max\n",
    "for key in channels.keys():\n",
    "    sorted_times_values = sorted(zip(channels[key]['times'], channels[key]['values']))\n",
    "    sorted_times, sorted_values = zip(*sorted_times_values)\n",
    "    channels[key]['values'] = list(sorted_values)\n",
    "    channels[key]['times'] = list(sorted_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRINT = False\n",
    "\n",
    "# Find the energy used from the buffer during the on-peak period\n",
    "first_values_buffer = []\n",
    "last_values_buffer = []\n",
    "for buffer_key in [x for x in channels if 'buffer' in x]:\n",
    "    if PRINT: \n",
    "        print('')\n",
    "        print(buffer_key)\n",
    "    # Find the value closest to the start of on-peak\n",
    "    differences = [abs(time - start_ms) for time in channels[buffer_key]['times'] if time < start_ms + 5*60*1000]\n",
    "    closest_index = differences.index(min(differences))\n",
    "    first_values_buffer.append(channels[buffer_key]['values'][closest_index])\n",
    "    if PRINT: print(f\"{first_values_buffer[-1]/1000} degC at {pendulum.from_timestamp(channels[buffer_key]['times'][closest_index]/1000, tz='America/New_York').replace(microsecond=0)}\")\n",
    "    # Find the value closest to the end of on-peak\n",
    "    differences = [abs(time - end_ms) for time in channels[buffer_key]['times']]\n",
    "    closest_index = differences.index(min(differences))\n",
    "    last_values_buffer.append(channels[buffer_key]['values'][closest_index])\n",
    "    if PRINT: print(f\"{last_values_buffer[-1]/1000} degC at {pendulum.from_timestamp(channels[buffer_key]['times'][closest_index]/1000, tz='America/New_York').replace(microsecond=0)}\")\n",
    "if len(first_values_buffer) != 4 or len(last_values_buffer) != 4:\n",
    "    print(\"Some buffer temperatures are missing\")\n",
    "else:\n",
    "    first_values_buffer = [x/1000 for x in first_values_buffer]\n",
    "    last_values_buffer = [x/1000 for x in last_values_buffer]\n",
    "    buffer_avg_before = sum(first_values_buffer)/4\n",
    "    buffer_avg_after = sum(last_values_buffer)/4\n",
    "    buffer_energy_used = 120 * 3.785 * 4.187/3600 * (buffer_avg_before - buffer_avg_after)\n",
    "\n",
    "# Find the energy used from the buffer during the on-peak period\n",
    "first_values_store = []\n",
    "last_values_store = []\n",
    "for store_key in [x for x in channels if 'tank' in x]:\n",
    "    if PRINT:\n",
    "        print('')\n",
    "        print(store_key)\n",
    "    # Get the closest value to start on onpeak\n",
    "    differences = [abs(time - start_ms) for time in channels[store_key]['times']]\n",
    "    closest_index = differences.index(min(differences))\n",
    "    first_values_store.append(channels[store_key]['values'][closest_index])\n",
    "    if PRINT: print(f\"{first_values_store[-1]/1000} degC at {pendulum.from_timestamp(channels[store_key]['times'][closest_index]/1000, tz='America/New_York').replace(microsecond=0)}\")\n",
    "    # Get the closest value to end of onpeak\n",
    "    differences = [abs(time - end_ms) for time in channels[store_key]['times']]\n",
    "    closest_index = differences.index(min(differences))\n",
    "    last_values_store.append(channels[store_key]['values'][closest_index])\n",
    "    if PRINT: print(f\"{last_values_store[-1]/1000} degC at {pendulum.from_timestamp(channels[store_key]['times'][closest_index]/1000, tz='America/New_York').replace(microsecond=0)}\")\n",
    "\n",
    "if len(first_values_store) != 12 or len(last_values_store) != 12:\n",
    "    print(\"Some storage temperatures are missing\")\n",
    "else:\n",
    "    first_values_store = [x/1000 for x in first_values_store]\n",
    "    last_values_store = [x/1000 for x in last_values_store]\n",
    "    store_avg_before = sum(first_values_store)/12\n",
    "    store_avg_after = sum(last_values_store)/12\n",
    "    store_energy_used = 3 * 120 * 3.785 * 4.187/3600 * (store_avg_before - store_avg_after)\n",
    "\n",
    "if PRINT: print('')\n",
    "print(f\"Energy from buffer: {round(buffer_energy_used,2)} kWh\") \n",
    "print(f\"Energy from storage: {round(store_energy_used,1)} kWh\")\n",
    "total_energy_used = store_energy_used+buffer_energy_used\n",
    "print(f\"Total energy used by house: {round(total_energy_used,1)} kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "def get_weather_data(latitude, longitude, start_time, end_time):    \n",
    "    \n",
    "    # Get the gridpoint info\n",
    "    url = f\"https://api.weather.gov/points/{latitude},{longitude}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching grid data: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    # Get the nearest observation station URL\n",
    "    grid_data = response.json()\n",
    "    station_url = grid_data['properties']['observationStations']\n",
    "    station_response = requests.get(station_url)\n",
    "    if station_response.status_code != 200:\n",
    "        print(f\"Error fetching station data: {station_response.status_code}\")\n",
    "        return []\n",
    "    \n",
    "    # Get the station ID (first station in the list)\n",
    "    stations = station_response.json()\n",
    "    station_id = stations['features'][0]['properties']['stationIdentifier']\n",
    "\n",
    "    # Get hourly observations from the station\n",
    "    observations_url = f\"https://api.weather.gov/stations/{station_id}/observations\"\n",
    "    params = {\n",
    "        'start': datetime.utcfromtimestamp(start_time).isoformat() + \"Z\",\n",
    "        'end': datetime.utcfromtimestamp(end_time).isoformat() + \"Z\"\n",
    "    }\n",
    "    observations_response = requests.get(observations_url, params=params)\n",
    "    if observations_response.status_code != 200:\n",
    "        print(f\"Error fetching observations data: {observations_response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    # Extract the relevant data (temperature, windSpeed)\n",
    "    observations = observations_response.json()\n",
    "    weather_data = {\n",
    "        'time': [],\n",
    "        'oat': [],\n",
    "        'ws': []\n",
    "    }\n",
    "    # print(observations['features'][0]['properties']['temperature']['unitCode'])\n",
    "    # print(observations['features'][0]['properties']['windSpeed']['unitCode'])\n",
    "    for observation in observations['features']:\n",
    "        weather_data['time'].append(datetime.fromisoformat(observation['properties']['timestamp']).astimezone(pytz.timezone('America/New_York')).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        weather_data['oat'].append(observation['properties']['temperature']['value'])\n",
    "        weather_data['ws'].append(observation['properties']['windSpeed']['value'])\n",
    "\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMLT_LAT, KMLT_LON = 45.6573, -68.7098\n",
    "from datetime import timezone\n",
    "import time\n",
    "\n",
    "def to_fahrenheit(t):\n",
    "    return (t * 9/5) + 32\n",
    "\n",
    "def to_mph(ws):\n",
    "    return ws * 0.621371\n",
    "\n",
    "def test():\n",
    "    # kmlt is the ICAO code for Millinocket\n",
    "    url = f\"https://api.weather.gov/points/{KMLT_LAT},{KMLT_LON}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching grid data: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    # Get the nearest observation station (this will be KMLT)\n",
    "    grid_data = response.json()\n",
    "    station_url = grid_data['properties']['observationStations']\n",
    "    station_response = requests.get(station_url)\n",
    "    if station_response.status_code != 200:\n",
    "        print(f\"Error fetching station data: {station_response.status_code}\")\n",
    "        return\n",
    "    stations = station_response.json()\n",
    "    station_id = stations['features'][0]['properties']['stationIdentifier']\n",
    "\n",
    "    # Get hourly observations from the station\n",
    "    observations_url = f\"https://api.weather.gov/stations/{station_id}/observations\"\n",
    "    start_time = time.time() - 60*60\n",
    "    end_time = time.time() + 5*60\n",
    "    params = {\n",
    "        'start': datetime.fromtimestamp(start_time, tz=timezone.utc).replace(tzinfo=None).isoformat() + \"Z\",\n",
    "        'end': datetime.fromtimestamp(end_time, tz=timezone.utc).replace(tzinfo=None).isoformat() + \"Z\"\n",
    "    }\n",
    "    observations_response = requests.get(observations_url, params=params)\n",
    "    if observations_response.status_code != 200:\n",
    "        print(f\"Error fetching observations data: {observations_response.status_code}\")\n",
    "        return\n",
    "    observations = observations_response.json()\n",
    "    if not observations:\n",
    "        print(\"Received no observations\")\n",
    "        return\n",
    "    # Take the latest observation\n",
    "    time_observed = observations['features'][-1]['properties']['timestamp']\n",
    "    time_observed = datetime.fromisoformat(time_observed).astimezone(pytz.timezone('America/New_York')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    oat_observed = round(to_fahrenheit(observations['features'][-1]['properties']['temperature']['value']),2)\n",
    "    wind_speed_observed = round(to_mph(observations['features'][-1]['properties']['windSpeed']['value']),2)\n",
    "    print(f\"\\nTime of latest observation: {time_observed}\")\n",
    "    print(f\"OAT: {oat_observed}, WS: {wind_speed_observed}\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get energy use forecast from weather and parameters\n",
    "ALPHA = 6\n",
    "BETA = -ALPHA/55\n",
    "GAMMA = 0.25\n",
    "\n",
    "def required_heating_power(oat, ws):\n",
    "    r = ALPHA + BETA*oat + GAMMA*ws\n",
    "    return r if r>0 else 0\n",
    "\n",
    "def to_fahrenheit(t):\n",
    "    return (t * 9/5) + 32\n",
    "\n",
    "def to_mph(ws):\n",
    "    return ws * 0.621371\n",
    "\n",
    "data = get_weather_data(45.6573, -68.7098, start_ms/1000, end_ms/1000)\n",
    "sorted_items = sorted(zip(data['time'], data['oat'], data['ws']), key=lambda x: datetime.strptime(x[0], '%Y-%m-%d %H:%M:%S'))\n",
    "weather_data = {'time': [], 'oat': [], 'ws': []}\n",
    "for time, oat, ws in sorted_items:\n",
    "    weather_data['time'].append(time)\n",
    "    weather_data['oat'].append(to_fahrenheit(oat))\n",
    "    weather_data['ws'].append(to_mph(ws))\n",
    "print(weather_data['oat'])\n",
    "print(weather_data['ws'])\n",
    "\n",
    "required_heat = 0\n",
    "for i in range(5):\n",
    "    required_heat += required_heating_power(weather_data['oat'][i], weather_data['ws'][i])\n",
    "\n",
    "print(f\"\\nUsed: {round(total_energy_used,2)}\")\n",
    "print(f\"Predicted: {round(required_heat,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When there is almost no wind (0-3mph), we are predicting way to high energy use\n",
    "# When there is some wind (10-20) we are doing good\n",
    "# Again when there is less wind (4-7) we are pedicting too high energy use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "daily_dp = [50.13] * 7 + [487.63] * 5 + [54.98] * 4 + [487.63] * 4 + [50.13] * 4\n",
    "plt.step(range(24), daily_dp)\n",
    "\n",
    "daily_dp = [price + i*(1 if i<7 else 0) for price, i in zip(daily_dp, list(range(24)))]\n",
    "daily_dp = [price + (i-11)*(1 if (i>11 and i<16) else 0) for price, i in zip(daily_dp, list(range(24)))]\n",
    "daily_dp = [price + (i-19)*(1 if (i>19) else 0) for price, i in zip(daily_dp, list(range(24)))]\n",
    "plt.step(range(24), daily_dp)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "settings = Settings(_env_file=dotenv.find_dotenv())\n",
    "valid_password = settings.visualizer_api_password.get_secret_value()\n",
    "engine = create_engine(settings.db_url.get_secret_value())\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "weather_messages = session.query(MessageSql).filter(\n",
    "    MessageSql.from_alias.like(f'%{house_alias}%'),\n",
    "    MessageSql.message_type_name == \"weather.forecast\",\n",
    "    MessageSql.message_persisted_ms >= start_ms,\n",
    "    MessageSql.message_persisted_ms <= end_ms,\n",
    ").order_by(asc(MessageSql.message_persisted_ms)).all()\n",
    "\n",
    "oat_forecasts, ws_forecasts = {}, {}\n",
    "for message in weather_messages:\n",
    "    forecast_start_time = int((message.message_persisted_ms/1000 // 3600) * 3600)\n",
    "    oat_forecasts[forecast_start_time] = message.payload['OatF']\n",
    "    ws_forecasts[forecast_start_time] = message.payload['WindSpeedMph']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "for weather_time in oat_forecasts:\n",
    "    forecast_times = [int(weather_time) + 3600*i for i in range(len(oat_forecasts[weather_time]))]\n",
    "    forecast_times = [datetime.fromtimestamp(x, tz=pytz.timezone(\"America/New_York\")) for x in forecast_times]\n",
    "    plt.plot(forecast_times, oat_forecasts[weather_time], alpha=0.2, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pendulum\n",
    "\n",
    "start_ms = pendulum.datetime(2025, 1, 21, 23, tz=\"America/New_York\").timestamp() * 1000 \n",
    "end_ms = pendulum.datetime(2025, 1, 21, 7, tz=\"America/New_York\").timestamp() * 1000 \n",
    "\n",
    "settings = Settings(_env_file=dotenv.find_dotenv())\n",
    "valid_password = settings.visualizer_api_password.get_secret_value()\n",
    "engine = create_engine(settings.db_url.get_secret_value())\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "msg: MessageSql = session.query(MessageSql).filter(\n",
    "    MessageSql.from_alias.like(f'%{house_alias}%'),\n",
    "    MessageSql.message_type_name == \"report\",\n",
    "    MessageSql.message_persisted_ms >= start_ms,\n",
    "    MessageSql.message_persisted_ms <= end_ms,\n",
    ").order_by(asc(MessageSql.message_persisted_ms)).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto.h.n.relay17\n",
      "auto.pico-cycler.relay1\n",
      "auto.h.n.relay9\n",
      "auto.h.n.relay2\n",
      "auto.h.n.relay8\n",
      "auto.h.n.relay12\n",
      "auto.h.n.relay11\n",
      "auto.h.n.relay20\n",
      "auto.h.n.relay21\n",
      "auto.h.n.relay3\n",
      "auto.h.n.relay18\n",
      "auto.h.n.relay24\n",
      "auto.h.n.relay23\n",
      "auto.h.n.relay6\n",
      "HP is off\n",
      "auto.h.n.relay22\n",
      "auto.h.n.relay5\n",
      "auto.h.n.relay19\n",
      "auto.pico-cycler\n",
      "s\n",
      "auto\n"
     ]
    }
   ],
   "source": [
    "from gwproto.enums.relay_closed_or_open import RelayClosedOrOpen\n",
    "\n",
    "for machine_state in msg.payload['StateList']:\n",
    "    ms = machine_state\n",
    "    if 'relay6' in ms['MachineHandle']:\n",
    "        if ms['StateList'][-1] == RelayClosedOrOpen.RelayClosed:\n",
    "            print(\"HP is off\")\n",
    "        else:\n",
    "            print(\"HP is on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
