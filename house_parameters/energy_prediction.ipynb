{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading json file...\n",
      "Opened messages from json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pendulum\n",
    "from sklearn.model_selection import train_test_split\n",
    "from energy_usage import energy_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1m/zr3l918x2s76ccl63lx5cst40000gn/T/ipykernel_9111/2698226209.py:3: DtypeWarning: Columns (8,26,32,33,34,35,37,38,47,48,49,55,57,64,65,75,77,94,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv('weather_data.csv', header=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2053 rows with NaNs\n",
      "No data found\n"
     ]
    }
   ],
   "source": [
    "ONPEAK_HOURS = [7,8,9,10,11] + [16,17,18,19]\n",
    "\n",
    "df_raw = pd.read_csv('weather_data.csv', header=4)\n",
    "df_raw['Year'] = [2000+int(x.split('/')[-1]) for x in list(df_raw['Date'])]\n",
    "df_raw['HourlyDryBulbTemperature'] = pd.to_numeric(df_raw['HourlyDryBulbTemperature'], errors='coerce')\n",
    "df_raw['HourlyWetBulbTemperature'] = pd.to_numeric(df_raw['HourlyWetBulbTemperature'], errors='coerce')\n",
    "df_raw['HourlyWindSpeed'] = pd.to_numeric(df_raw['HourlyWindSpeed'], errors='coerce')\n",
    "df_raw['HourlyWindGustSpeed'] = pd.to_numeric(df_raw['HourlyWindGustSpeed'], errors='coerce')\n",
    "df_raw['HourlyWindDirection'] = pd.to_numeric(df_raw['HourlyWindDirection'], errors='coerce')\n",
    "df_raw['HourlyPrecipitation'] = pd.to_numeric(df_raw['HourlyPrecipitation'], errors='coerce')\n",
    "df_raw['HourlyRelativeHumidity'] = pd.to_numeric(df_raw['HourlyRelativeHumidity'], errors='coerce')\n",
    "df_raw['HourlyStationPressure'] = pd.to_numeric(df_raw['HourlyStationPressure'], errors='coerce')\n",
    "\n",
    "clean_data = {\n",
    "    'date': [x for x in list(df_raw['DATE'])],\n",
    "    'oat_dry': [x for x in list(df_raw['HourlyDryBulbTemperature'])],\n",
    "    'oat_wet': [x for x in list(df_raw['HourlyWetBulbTemperature'])],\n",
    "    'wind_speed': [x for x in list(df_raw['HourlyWindSpeed'])],\n",
    "    'wind_gust_speed': [0 if pd.isna(x) else x for x in list(df_raw['HourlyWindGustSpeed'])],\n",
    "    'wind_direction': [0 if pd.isna(x) else x for x in list(df_raw['HourlyWindDirection'])],\n",
    "    'precipitation': [x for x in list(df_raw['HourlyPrecipitation'])],\n",
    "    'humidity': [x for x in list(df_raw['HourlyRelativeHumidity'])],\n",
    "    'pressure': [x for x in list(df_raw['HourlyStationPressure'])],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(clean_data)\n",
    "\n",
    "# Add sky conditions\n",
    "all_codes = ['BKN', 'OVC', 'VV', 'SCT', 'FEW', 'CLR']\n",
    "sky_conditions = {}\n",
    "for code in all_codes:\n",
    "    sky_conditions[code] = [0]*len(df_raw)\n",
    "for k in range(len(df_raw)):\n",
    "    x = str(df_raw['HourlySkyConditions'][k])\n",
    "    for i in range(x.count(':')):\n",
    "        sky_conditions[x.split(':')[i][-3:]][k] = 1\n",
    "for key in sky_conditions:\n",
    "    df[key] = sky_conditions[key]\n",
    "\n",
    "# plt.scatter(range(len(df)), df['date'].dt.minute)\n",
    "# plt.show()\n",
    "\n",
    "# Group data by hour, taking the mean\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%dT%H:%M:%S')\n",
    "df['date_grouped'] = df['date'].dt.strftime('%Y-%m-%d %H')\n",
    "df = df.groupby('date_grouped').mean()\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = df.round(1)\n",
    "\n",
    "# Drop rows which contain NaNs\n",
    "num_nans = len(df)\n",
    "df = df.dropna()\n",
    "num_nans = num_nans - len(df)\n",
    "print(f\"There were {num_nans} rows with NaNs\")\n",
    "\n",
    "# Only keep data for the selected time\n",
    "df_backup = df.copy()\n",
    "df = df[df['date'] >= pendulum.datetime(2024, 12, 3, tz='America/New_York').naive()]\n",
    "# df = df[df['date'] <= pendulum.datetime(2024, 12, 5, tz='America/New_York').naive()]\n",
    "df = df[df['date'].dt.hour.isin(ONPEAK_HOURS)]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Find the energy used\n",
    "df['energy'] = df.apply(lambda row: \n",
    "                             energy_used('beech', row['date'].year, row['date'].month, row['date'].day, row['date'].hour), \n",
    "                             axis=1\n",
    "                             )\n",
    "df['date'] = df['date'].dt.floor('h')\n",
    "\n",
    "# Drop rows which contain NaNs again\n",
    "num_nans = len(df)\n",
    "df = df.dropna()\n",
    "num_nans = num_nans - len(df)\n",
    "print(f\"There were {num_nans} rows with NaNs\")\n",
    "\n",
    "print(df)\n",
    "\n",
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_backup.copy()\n",
    "plt.figure(figsize=(16,4))\n",
    "\n",
    "# Predict energy used by the house using alpha, beta, gamma formula\n",
    "alpha, beta, gamma = 9.8, -0.18, 0.005\n",
    "def energy_alpha_pred(oat, ws):\n",
    "    return alpha + beta*oat + gamma*ws\n",
    "df['energy_pred_alpha'] = df.apply(lambda row: energy_alpha_pred(row['oat_dry'], row['wind_speed']), axis=1)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for kwh in [125]:#range(50,200,25):\n",
    "    kwh = kwh/100\n",
    "    print(kwh)\n",
    "\n",
    "    # Update the energy column in both the training and testing set\n",
    "    df['energy'] = df.apply(lambda row: \n",
    "                             energy_used('beech', row['date'].year, row['date'].month, row['date'].day, row['date'].hour, thermal_mass=kwh), \n",
    "                             axis=1\n",
    "                             )\n",
    "    \n",
    "    print(f\"{start_time-time.time()}\")\n",
    "    \n",
    "    # Split training and testing data\n",
    "    features = [col for col in df.columns if col not in ['energy', 'date', 'energy_pred_alpha'] and 'energy' not in col]\n",
    "    X = df[features]\n",
    "    y = df['energy']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    test_df = pd.concat([X_test, y_test, df.loc[X_test.index, 'date']], axis=1)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    import statsmodels.formula.api as smf\n",
    "    binary_columns = [x for x in df.columns if x in all_codes]\n",
    "    for col in binary_columns:\n",
    "        df[col] = df[col].round().astype('category')\n",
    "    formula = 'energy ~ oat_dry + wind_speed'\n",
    "    mod = smf.ols(formula=formula, data=train_df)\n",
    "    res = mod.fit()\n",
    "    print(res.summary())\n",
    "\n",
    "    # DATES FOR THE PLOT ----------------------------\n",
    "    # DATES FOR THE PLOT ----------------------------\n",
    "    # df = df[df['date'] >= pendulum.datetime(2025, 1, 10, 0, tz='America/New_York').naive()]\n",
    "    # df = df[df['date'] <= pendulum.datetime(2025, 1, 1, 0, tz='America/New_York').naive()]\n",
    "    # DATES FOR THE PLOT ----------------------------\n",
    "    # DATES FOR THE PLOT ----------------------------\n",
    "\n",
    "    # Predict the testing data\n",
    "    test_df = df.copy()\n",
    "    test_df['energy_pred_reg'] = res.predict(test_df)\n",
    "    df = df.sort_values(by='date')\n",
    "\n",
    "    # Plot\n",
    "    color = 'tab:blue' if kwh==0 else 'tab:orange'\n",
    "    line_style='-'\n",
    "    plt.plot(test_df.date, test_df.energy, line_style, label=f'used - {kwh} kWh/degF', alpha=0.4, color=color)\n",
    "    rmse_reg = round(((test_df['energy'] - test_df['energy_pred_reg'])**2).mean()**0.5,2)\n",
    "    print(rmse_reg)\n",
    "    plt.plot(test_df.date, test_df.energy_pred_reg, linestyle='dashed', label=f'predicted - {kwh} kWh/degF, RMSE={rmse_reg}', alpha=0.6, color=color)\n",
    "\n",
    "plt.ylim([-0.1,16])\n",
    "plt.ylabel('Heat [kWh]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Using random forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=2)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Predict on the testing data\n",
    "# test_df = df.copy()\n",
    "# test_df['energy_pred_reg'] = res.predict(test_df)\n",
    "# # test_df['energy_pred_rf'] = rf_regressor.predict(test_df[features])\n",
    "# test_df['energy_pred_alpha'] = test_df.apply(lambda row: energy_alpha_pred(row['oat_dry'], row['wind_speed']), axis=1)\n",
    "# test_df = test_df.sort_values(by='date')\n",
    "\n",
    "# plt.figure(figsize=(16,4))\n",
    "# plt.plot(test_df.date, test_df.energy, '-o', label='used', alpha=0.7, color='gray')\n",
    "# plt.scatter(test_df.date, test_df.energy_pred_alpha, label='predicted - alpha', alpha=0.7)\n",
    "# plt.scatter(test_df.date, test_df.energy_pred_reg, label='predicted - new', alpha=0.7)\n",
    "# # plt.scatter(test_df.date, test_df.energy_pred_rf, label='predicted - rf', alpha=0.7)\n",
    "\n",
    "# # for day in test_df.date.dt.date.unique():\n",
    "# #     start_time = pd.to_datetime(day).replace(hour=7, minute=0, second=0, microsecond=0)\n",
    "# #     end_time = pd.to_datetime(day).replace(hour=12, minute=0, second=0, microsecond=0)\n",
    "# #     plt.axvspan(start_time, end_time, color='gray', alpha=0.1)\n",
    "\n",
    "# # for day in test_df.date.dt.date.unique():\n",
    "# #     start_time = pd.to_datetime(day).replace(hour=16, minute=0, second=0, microsecond=0)\n",
    "# #     end_time = pd.to_datetime(day).replace(hour=20, minute=0, second=0, microsecond=0)\n",
    "# #     plt.axvspan(start_time, end_time, color='gray', alpha=0.1)\n",
    "\n",
    "# plt.ylim([-0.1,16])\n",
    "# plt.ylabel('Heat [kWh]')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot weather\n",
    "# plt.figure(figsize=(16,4))\n",
    "# df_trick = df.copy()\n",
    "# plt.plot(df_trick['date'], df_trick['oat_dry'], '-x', label=\"oat_dry\")\n",
    "# plt.plot(df_trick['date'], df_trick['oat_wet'], '-x', label=\"oat_wet\")\n",
    "# plt.plot(df_trick['date'], df_trick['wind_speed'], '-x', label=\"wind_speed\")\n",
    "# plt.plot(df_trick['date'], df_trick['wind_gust_speed'], '-x', label=\"wind_gust_speed\")\n",
    "# # plt.plot(df_trick['date'], df_trick['humidity'], '-x', label=\"humidity\")\n",
    "# # plt.plot(df_trick['date'], df_trick['wind_direction'], '-x', label=\"wind_direction\")\n",
    "# plt.plot(df_trick['date'], df_trick['FEW'], '-x', label=\"FEW\")\n",
    "# plt.ylabel('Various')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot lines\n",
    "# plt.figure(figsize=(16,4))\n",
    "# line_style='-'\n",
    "# plt.plot(test_df.date, test_df.energy, line_style, label='used', alpha=0.4, color='gray')\n",
    "# rmse_alpha = round(((test_df['energy'] - test_df['energy_pred_alpha'])**2).mean()**0.5,2)\n",
    "# rmse_reg = round(((test_df['energy'] - test_df['energy_pred_reg'])**2).mean()**0.5,2)\n",
    "# # rmse_rf = round(((test_df['energy'] - test_df['energy_pred_rf'])**2).mean()**0.5,2)\n",
    "# # plt.plot(test_df.date, test_df.energy_pred_alpha, line_style, label=f'predicted - alpha/beta/gamma, RMSE={rmse_alpha}', alpha=0.6)\n",
    "# plt.plot(test_df.date, test_df.energy_pred_reg, line_style, label=f'predicted - new, RMSE={rmse_reg}', alpha=0.6)\n",
    "# # plt.plot(test_df.date, test_df.energy_pred_rf, line_style, label=f'predicted - rf, RMSE={rmse_rf}', alpha=0.6)\n",
    "# plt.ylim([-0.1,16])\n",
    "# plt.ylabel('Heat [kWh]')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the trained Random Forest model\n",
    "feature_importances = rf_regressor.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': feature_importances\n",
    "})\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the RFE with RandomForestRegressor as the estimator\n",
    "selector = RFE(estimator=RandomForestRegressor(), n_features_to_select=1)\n",
    "\n",
    "# Fit the RFE to the training data\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the ranking of features (1 means the feature is the most important)\n",
    "feature_ranking = pd.DataFrame({\n",
    "    'Ranking': selector.ranking_,\n",
    "    'Feature': X_train.columns,\n",
    "})\n",
    "\n",
    "# Sort by the ranking to see which features are most important\n",
    "feature_ranking = feature_ranking.sort_values(by='Ranking')\n",
    "display(feature_ranking)\n",
    "\n",
    "# Get the selected features based on RFE\n",
    "selected_features = X_train.columns[selector.support_]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Reduce the features in the dataset\n",
    "X_train_selected = X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the residuals from predicting with OAT are correlated to the other feautres\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Estimate energy from OAT only\n",
    "formula = 'energy ~ oat_dry'\n",
    "mod = smf.ols(formula=formula, data=train_df)\n",
    "res = mod.fit()\n",
    "\n",
    "test_df['energy_from_oat'] = res.predict(test_df)\n",
    "test_df['residuals'] = test_df['energy'] - test_df['energy_from_oat']\n",
    "\n",
    "features, correlations, pvalues = [], [], []\n",
    "for col in [x for x in test_df.columns if x not in ['date', 'oat_dry', 'residuals', 'VV'] and 'energy' not in x]:\n",
    "    corr, p_value = stats.spearmanr(test_df['residuals'], test_df[col])\n",
    "    features.append(col)\n",
    "    correlations.append(corr)\n",
    "    pvalues.append(p_value)\n",
    "\n",
    "residual_correlation = pd.DataFrame({'feature': features, 'correlation': correlations, 'p-value': pvalues})\n",
    "residual_correlation.sort_values(by='p-value').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df['wind_speed'][24:48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
